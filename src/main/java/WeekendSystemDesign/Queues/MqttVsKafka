PUSH AND CONSUMER PREFETCH

Exchanges and Queues
RabbitMQ

RabbitMQ is a distributed message queue system. Distributed because it is usually run as a cluster of nodes where queues are spread across the nodes and optionally replicated for fault tolerance and high availability.
It natively implements AMQP 0.9.1 and offers other protocols such as STOMP, MQTT and HTTP via plug-ins.

RabbitMQ takes both a classic and a novel take on messaging. Classic in the sense that it is oriented around message queues, and novel in its highly flexible routing capability. It is this routing capability that is its killer feature. Building a fast, scalable, reliable distributed messaging system is an achievement in itself, but the message routing functionality is what makes it truly stand out among the myriad of messaging technologies out there.

The super simplified overview:

    Publishers send messages to exchanges
    Exchanges route messages to queues and other exchanges
    RabbitMQ sends acknowledgements to publishers on message receipt
    Consumers maintain persistent TCP connections with RabbitMQ and declare which queue(s) they consume
    RabbitMQ pushes messages to consumers
    Consumers send acknowledgements of success/failure
    Messages are removed from queues once consumed successfully

1)RabbitMQ pushes messages to consumers (there is a pull API but it is deprecated). This could overwhelm the consumers if messages arrive at the queue faster than the consumers can process them. So to avoid this each consumer can configure a prefetch limit (also known as a QoS limit).  This basically is the number of unacknowledged messages that a consumer can have at any one time. This acts as a safety cut off switch for when the consumer starts to fall behind.

Why push and not pull?
First of all it is great for low latency.
Secondly, ideally when we have competing consumers of a single
queue we want to distribute load evenly between them.
If each consumer pulls messages then depending on how many they pull
the distribution of work can get pretty uneven.
The more uneven the distribution of messages the more latency and the further the loss of message order at processing time. These factors make RabbitMQ lean towards a one message at a time push mechanism. This is one of the scaling limitations of RabbitMQ. It is ameliorated by being able to group acknowledgements together.


